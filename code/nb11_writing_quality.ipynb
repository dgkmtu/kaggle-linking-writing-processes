{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59291,"databundleVersionId":6678907,"sourceType":"competition"},{"sourceId":6971449,"sourceType":"datasetVersion","datasetId":3992884},{"sourceId":6973319,"sourceType":"datasetVersion","datasetId":3949123},{"sourceId":150384981,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 目的\n\n本コンペティションは、学生にエッセイを書かせ、その詳細な動作(入力や消去、移動など)からエッセイの採点結果を予想するテーブルコンペである。  \n  \nこのnotebookでは、前処理から学習、提出までの流れをまとめる。  \nなお、参考にしたnotebookは以下の通り。  \n[https://www.kaggle.com/code/alexryzhkov/lgbm-and-nn-on-sentences/notebook](https://www.kaggle.com/code/alexryzhkov/lgbm-and-nn-on-sentences/notebook)","metadata":{}},{"cell_type":"markdown","source":"## 1. LightAutoMLのインストール\n事前に[LightAutoML 038 dependecies](https://www.kaggle.com/code/alexryzhkov/lightautoml-038-dependecies)をAdd Dataしておく。","metadata":{}},{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies lightautoml==0.3.8\n!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies pandas==2.0.3","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-30T12:17:03.124191Z","iopub.execute_input":"2023-11-30T12:17:03.124556Z","iopub.status.idle":"2023-11-30T12:17:43.093514Z","shell.execute_reply.started":"2023-11-30T12:17:03.124516Z","shell.execute_reply":"2023-11-30T12:17:43.092243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/lightautoml-0.3.8-py3-none-any.whl\nProcessing /kaggle/input/lightautoml-038-dependecies/AutoWoE-1.3.2-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/cmaes-0.10.0-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.24)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/joblib-1.2.0-py3-none-any.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/json2html-1.3.0.tar.gz (from lightautoml==0.3.8)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing /kaggle/input/lightautoml-038-dependecies/lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (from lightautoml==0.3.8)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.24.3)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.4.0)\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/poetry_core-1.8.1-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (6.0.1)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.12.2)\nRequirement already satisfied: statsmodels<=0.14.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.14.0)\nRequirement already satisfied: torch<=2.0.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (2.0.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (4.66.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/StrEnum-0.4.15-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (3.7.3)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (7.4.3)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (2023.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (1.11.3)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinx-7.2.6-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (0.2.4)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (5.16.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (1.16.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml==0.3.8) (0.41.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml==0.3.8) (2.8.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (0.5.3)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.12)\nRequirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (2.3.1)\nRequirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (0.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml==0.3.8) (2.1.3)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (1.12.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (6.7.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (2.0.20)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml==0.3.8) (2.0.2)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml==0.3.8) (8.2.3)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.2.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.1.3)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.16.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.12.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/alabaster-0.7.13-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/imagesize-1.4.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.31.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (2023.7.22)\nBuilding wheels for collected packages: json2html\n  Building wheel for json2html (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7591 sha256=6dd2bac2edb74f3e71dfc5582d5e5c231f04827ac848adff1b8a6c02b7b030b8\n  Stored in directory: /root/.cache/pip/wheels/03/04/0d/34912ecabd9128a537a032c0fc15c6c46e734fb5fe3a14536c\nSuccessfully built json2html\nInstalling collected packages: StrEnum, json2html, sphinxcontrib-jsmath, poetry-core, joblib, imagesize, cmaes, alabaster, pandas, lightgbm, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, autowoe, lightautoml\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.3.2\n    Uninstalling joblib-1.3.2:\n      Successfully uninstalled joblib-1.3.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.0.3\n    Uninstalling pandas-2.0.3:\n      Successfully uninstalled pandas-2.0.3\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 3.3.2\n    Uninstalling lightgbm-3.3.2:\n      Successfully uninstalled lightgbm-3.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-0.7.13 autowoe-1.3.2 cmaes-0.10.0 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8 lightgbm-3.2.1 pandas-1.5.3 poetry-core-1.8.1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\nLooking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\nInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Uninstalling pandas-1.5.3:\n      Successfully uninstalled pandas-1.5.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nlightautoml 0.3.8 requires pandas<2.0.0, but you have pandas 2.0.3 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-2.0.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Import","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport gc\nimport os\nimport itertools\nimport pickle\nimport re\nimport time\nfrom random import choice, choices\nfrom functools import reduce\nfrom tqdm import tqdm\nfrom itertools import cycle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom functools import reduce\nfrom itertools import cycle\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nfrom sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\nimport lightgbm as lgb\nimport copy","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:43.095817Z","iopub.execute_input":"2023-11-30T12:17:43.096160Z","iopub.status.idle":"2023-11-30T12:17:46.572275Z","shell.execute_reply.started":"2023-11-30T12:17:43.096125Z","shell.execute_reply":"2023-11-30T12:17:46.571219Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 3. データの読み込み\n初期に用意される入力データは、以下の4つが用意されている。\n- train_logs.csv : キーロガーの記録(学習データ)\n- train_scores.csv : エッセイの採点結果(学習データ)\n- test_logs.csv : キーロガーの記録(テストデータ)\n- sample_submission.csv : 提出用csvファイル","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = '../input/linking-writing-processes-to-writing-quality'\ntrain_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\ntrain_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\ntest_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\nss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:46.573711Z","iopub.execute_input":"2023-11-30T12:17:46.574023Z","iopub.status.idle":"2023-11-30T12:17:57.265855Z","shell.execute_reply.started":"2023-11-30T12:17:46.573996Z","shell.execute_reply":"2023-11-30T12:17:57.264570Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"読み込んだデータの概要を確認する。  \n各データの形状および先頭5行をみると、train_logsとtest_logsには「生徒のid」や「アクションの開始・終了の時間」、「アクションの種類(InputやRemoveなど)」などの情報が格納されている。  \n一方で、train_scoresには「生徒のid」と「エッセイの採点結果」が格納されている。  \n提出の形式は、「生徒のid」および「エッセイの採点結果」を提出するようだ。","metadata":{}},{"cell_type":"code","source":"print(\"train_logs shape : \", train_logs.shape)\nprint(\"train_scores shape : \", train_scores.shape)\nprint(\"test_logs shape : \", test_logs.shape)\nprint(\"sample_submission shape : \", ss_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.268277Z","iopub.execute_input":"2023-11-30T12:17:57.268564Z","iopub.status.idle":"2023-11-30T12:17:57.273900Z","shell.execute_reply.started":"2023-11-30T12:17:57.268540Z","shell.execute_reply":"2023-11-30T12:17:57.272872Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train_logs shape :  (8405898, 11)\ntrain_scores shape :  (2471, 2)\ntest_logs shape :  (6, 11)\nsample_submission shape :  (3, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"display(train_logs.head())\ndisplay(train_scores.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.274840Z","iopub.execute_input":"2023-11-30T12:17:57.275322Z","iopub.status.idle":"2023-11-30T12:17:57.311464Z","shell.execute_reply.started":"2023-11-30T12:17:57.275047Z","shell.execute_reply":"2023-11-30T12:17:57.310108Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id  event_id  down_time  up_time  action_time       activity  \\\n0  001519c8         1       4526     4557           31  Nonproduction   \n1  001519c8         2       4558     4962          404  Nonproduction   \n2  001519c8         3     106571   106571            0  Nonproduction   \n3  001519c8         4     106686   106777           91          Input   \n4  001519c8         5     107196   107323          127          Input   \n\n  down_event   up_event text_change  cursor_position  word_count  \n0  Leftclick  Leftclick    NoChange                0           0  \n1  Leftclick  Leftclick    NoChange                0           0  \n2      Shift      Shift    NoChange                0           0  \n3          q          q           q                1           1  \n4          q          q           q                2           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>1</td>\n      <td>4526</td>\n      <td>4557</td>\n      <td>31</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001519c8</td>\n      <td>2</td>\n      <td>4558</td>\n      <td>4962</td>\n      <td>404</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001519c8</td>\n      <td>3</td>\n      <td>106571</td>\n      <td>106571</td>\n      <td>0</td>\n      <td>Nonproduction</td>\n      <td>Shift</td>\n      <td>Shift</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001519c8</td>\n      <td>4</td>\n      <td>106686</td>\n      <td>106777</td>\n      <td>91</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001519c8</td>\n      <td>5</td>\n      <td>107196</td>\n      <td>107323</td>\n      <td>127</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         id  score\n0  001519c8    3.5\n1  0022f953    3.5\n2  0042269b    6.0\n3  0059420b    2.0\n4  0075873a    4.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022f953</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0042269b</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0059420b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0075873a</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"display(test_logs.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.314888Z","iopub.execute_input":"2023-11-30T12:17:57.315211Z","iopub.status.idle":"2023-11-30T12:17:57.329828Z","shell.execute_reply.started":"2023-11-30T12:17:57.315187Z","shell.execute_reply":"2023-11-30T12:17:57.328484Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id  event_id  down_time  up_time  action_time activity down_event  \\\n0  0000aaaa         1     338433   338518           85    Input      Space   \n1  0000aaaa         2     760073   760160           87    Input      Space   \n2  2222bbbb         1     711956   712023           67    Input          q   \n3  2222bbbb         2     290502   290548           46    Input          q   \n4  4444cccc         1     635547   635641           94    Input      Space   \n\n  up_event text_change  cursor_position  word_count  \n0    Space                            0           0  \n1    Space                            1           0  \n2        q           q                0           1  \n3        q           q                1           1  \n4    Space                            0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>1</td>\n      <td>338433</td>\n      <td>338518</td>\n      <td>85</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000aaaa</td>\n      <td>2</td>\n      <td>760073</td>\n      <td>760160</td>\n      <td>87</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222bbbb</td>\n      <td>1</td>\n      <td>711956</td>\n      <td>712023</td>\n      <td>67</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2222bbbb</td>\n      <td>2</td>\n      <td>290502</td>\n      <td>290548</td>\n      <td>46</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4444cccc</td>\n      <td>1</td>\n      <td>635547</td>\n      <td>635641</td>\n      <td>94</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"続いて、作成したエッセイの情報を読み込む。  \nこの情報はtrain_logsのキーロガー情報を結合し、各生徒が作成したエッセイを復元したデータである。実際に入力した文字は\"q\"に置き換えられているが、エッセイの長さなどの重要な情報が取得可能となる。  \n\n<参考>  \n[https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features](https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features)","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv('../input/writing-quality-challenge-constructed-essays/train_essays_02.csv')\ntrain_essays.index = train_essays[\"Unnamed: 0\"]\ntrain_essays.index.name = None\ntrain_essays.drop(columns=[\"Unnamed: 0\"], inplace=True)\ntrain_essays.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.331507Z","iopub.execute_input":"2023-11-30T12:17:57.331953Z","iopub.status.idle":"2023-11-30T12:17:57.440672Z","shell.execute_reply.started":"2023-11-30T12:17:57.331913Z","shell.execute_reply":"2023-11-30T12:17:57.439980Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                      essay\n001519c8  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...\n0022f953  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...\n0042269b  qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...\n0059420b  qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...\n0075873a  qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>001519c8</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n    </tr>\n    <tr>\n      <th>0022f953</th>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n    </tr>\n    <tr>\n      <th>0042269b</th>\n      <td>qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...</td>\n    </tr>\n    <tr>\n      <th>0059420b</th>\n      <td>qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...</td>\n    </tr>\n    <tr>\n      <th>0075873a</th>\n      <td>qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"また、テストデータについてもエッセイを復元する。  \nテストデータのエッセイは、以下の関数を使用して新たにエッセイを復元する。\n- processingInputs関数 : 各キーロガー記録からテキストの小部分を復元する関数(getEssays関数内で呼び出される。)\n- getEssays関数 : エッセイを復元する関数","metadata":{}},{"cell_type":"code","source":"def getEssays(df):\n    \"\"\"\n    エッセイの復元関数\n    [input]\n     df(pd.DataFrame) : キーロガー情報のデータフレーム\n    [output]\n     essayFrame(pd.DataFrame) : 復元したエッセイのデータフレーム\n    \"\"\"\n    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n    lastIndex = 0\n    essaySeries = pd.Series()\n    for index, valCount in enumerate(valCountsArr):\n        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n        lastIndex += valCount\n        essayText = \"\"\n        for Input in currTextInput.values:\n            if Input[0] == 'Replace':\n                replaceTxt = Input[2].split(' => ')\n                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] +\\\n                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n                continue\n            if Input[0] == 'Paste':\n                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n                continue\n            if Input[0] == 'Remove/Cut':\n                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n                continue\n            if \"M\" in Input[0]:\n                croppedTxt = Input[0][10:]\n                splitTxt = croppedTxt.split(' To ')\n                valueArr = [item.split(', ') for item in splitTxt]\n                moveData = (int(valueArr[0][0][1:]), \n                            int(valueArr[0][1][:-1]), \n                            int(valueArr[1][0][1:]), \n                            int(valueArr[1][1][:-1]))\n                if moveData[0] != moveData[2]:\n                    if moveData[0] < moveData[2]:\n                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n                    else:\n                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n                continue\n            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n        essaySeries[index] = essayText\n    essaySeries.index =  textInputDf['id'].unique()\n    return pd.DataFrame(essaySeries, columns=['essay'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.441824Z","iopub.execute_input":"2023-11-30T12:17:57.442372Z","iopub.status.idle":"2023-11-30T12:17:57.457507Z","shell.execute_reply.started":"2023-11-30T12:17:57.442347Z","shell.execute_reply":"2023-11-30T12:17:57.455847Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Features for test dataset\ntest_essays = getEssays(test_logs)\ntest_essays.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.458468Z","iopub.execute_input":"2023-11-30T12:17:57.458815Z","iopub.status.idle":"2023-11-30T12:17:57.488706Z","shell.execute_reply.started":"2023-11-30T12:17:57.458789Z","shell.execute_reply":"2023-11-30T12:17:57.487432Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         essay\n0000aaaa      \n2222bbbb    qq\n4444cccc    q ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000aaaa</th>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2222bbbb</th>\n      <td>qq</td>\n    </tr>\n    <tr>\n      <th>4444cccc</th>\n      <td>q</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4.特徴量の作成","metadata":{}},{"cell_type":"markdown","source":"本節では、学習データを作成する準備として、各生徒のキーロガー情報から特徴量を作成していく。  \nまず、最初の準備としては復元したエッセイ情報からエッセイの特徴に関する情報（文字数や平均文字数などの情報）を作成する。  \nここでは四分位数の第一四分位数と第三四分位数を求める関数と、復元したテキスト情報から、エッセイの情報を抜き出す関数を定義する。  \n- q1関数 : 第一四分位数(25パーセンタイル)を返却する関数\n- q3関数 : 第三四分位数(75パーセンタイル)を返却する関数\n- split_essays_into_sentences関数 : 復元したエッセイを各文ごとに分割し、その文章の長さや単語数を返却する関数\n- compute_sentence_aggregations関数 : 各文ごとに分割したエッセイ情報から文字数や平均文字数などの情報を返却する関数","metadata":{}},{"cell_type":"code","source":"# 第一四分位数と第三四分位数を返却する関数\ndef q1(x):\n    return x.quantile(0.25)\ndef q3(x):\n    return x.quantile(0.75)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.492201Z","iopub.execute_input":"2023-11-30T12:17:57.492510Z","iopub.status.idle":"2023-11-30T12:17:57.498918Z","shell.execute_reply.started":"2023-11-30T12:17:57.492483Z","shell.execute_reply":"2023-11-30T12:17:57.497761Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', pd.DataFrame.kurt, 'sum']\n\ndef split_essays_into_sentences(df):\n    \"\"\"\n    エッセイ情報の各文別データフレーム作成関数\n    [input]\n     df(pd.DataFrame) : 復元したエッセイのデータフレーム\n    [output]\n     essay_df(pd.DataFrame) : 復元したエッセイのデータフレーム\n     \n    復元したエッセイ情報をもとに文の最後にあるカンマ(.)をキーとしてエッセイを分割する。\n    分割した各文の情報およびそれぞれの文章の長さや単語数の情報を追加して返却する。\n    \"\"\"\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n    essay_df = essay_df.explode('sent')\n    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n    # Number of characters in sentences\n    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n    # Number of words in sentences\n    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.sent_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_sentence_aggregations(df):\n    \"\"\"\n    エッセイ情報の統計情報取得関数\n    [input]\n     df(pd.DataFrame) : 復元したエッセイのデータフレーム\n    [output]\n     sent_agg_df(pd.DataFrame) : 復元したエッセイのデータフレーム\n     \n    カンマ(.)をキーとして分割したエッセイ情報のデータフレームから、生徒ごとの統計情報(平均や分散など)を\n    取得し返却する。\n    \"\"\"\n    sent_agg_df = pd.concat(\n        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    )\n    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n    sent_agg_df['id'] = sent_agg_df.index\n    sent_agg_df = sent_agg_df.reset_index(drop=True)\n    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n    return sent_agg_df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.500394Z","iopub.execute_input":"2023-11-30T12:17:57.500768Z","iopub.status.idle":"2023-11-30T12:17:57.512009Z","shell.execute_reply.started":"2023-11-30T12:17:57.500739Z","shell.execute_reply":"2023-11-30T12:17:57.510748Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Word features for train dataset\ntrain_sent_df = split_essays_into_sentences(train_essays)\ntrain_sent_agg_df = compute_sentence_aggregations(train_sent_df)\ntest_sent_df = split_essays_into_sentences(test_essays)\ntest_sent_agg_df = compute_sentence_aggregations(test_sent_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:17:57.513245Z","iopub.execute_input":"2023-11-30T12:17:57.514382Z","iopub.status.idle":"2023-11-30T12:18:03.351915Z","shell.execute_reply.started":"2023-11-30T12:17:57.514342Z","shell.execute_reply":"2023-11-30T12:18:03.350642Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"この関数を実行することで、各エッセイにおける各文の統計量が特徴量として取得できる。","metadata":{}},{"cell_type":"code","source":"display(train_sent_agg_df.head())\ndisplay(test_sent_agg_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:03.353199Z","iopub.execute_input":"2023-11-30T12:18:03.353517Z","iopub.status.idle":"2023-11-30T12:18:03.387041Z","shell.execute_reply.started":"2023-11-30T12:18:03.353490Z","shell.execute_reply":"2023-11-30T12:18:03.386368Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"   sent_count  sent_len_mean  sent_len_std  sent_len_min  sent_len_max  \\\n0          14     106.142857     41.128050            31           196   \n1          15     107.666667     64.713287            19           226   \n2          19     133.842105     33.480115            73           189   \n3          13      86.846154     33.195999            39           144   \n4          16      86.812500     44.094170            22           182   \n\n   sent_len_first  sent_len_last  sent_len_sem  sent_len_q1  sent_len_median  \\\n0              31             89     10.991934         75.5            119.5   \n1              19            143     16.708899         56.5             92.0   \n2             139            161      7.680865        108.0            139.0   \n3              99             80      9.206914         62.0             80.0   \n4              75             22     11.023543         60.0             74.0   \n\n   ...  sent_word_count_first  sent_word_count_last  sent_word_count_sem  \\\n0  ...                      6                    16             1.736577   \n1  ...                      3                    30             3.269872   \n2  ...                     21                    26             1.207599   \n3  ...                     17                    14             1.800997   \n4  ...                     11                     3             2.166927   \n\n   sent_word_count_q1  sent_word_count_median  sent_word_count_q3  \\\n0               12.25                    21.0               22.00   \n1               12.00                    20.0               31.00   \n2               17.50                    21.0               26.50   \n3               11.00                    15.0               18.00   \n4               11.00                    12.5               18.25   \n\n   sent_word_count_skew  sent_word_count_kurt  sent_word_count_sum        id  \n0             -0.506007             -0.526754                  256  001519c8  \n1              0.391857             -0.935036                  325  0022f953  \n2             -0.242560             -1.171619                  408  0042269b  \n3              0.656055             -0.538051                  208  0059420b  \n4              1.148513              0.888421                  255  0075873a  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_count</th>\n      <th>sent_len_mean</th>\n      <th>sent_len_std</th>\n      <th>sent_len_min</th>\n      <th>sent_len_max</th>\n      <th>sent_len_first</th>\n      <th>sent_len_last</th>\n      <th>sent_len_sem</th>\n      <th>sent_len_q1</th>\n      <th>sent_len_median</th>\n      <th>...</th>\n      <th>sent_word_count_first</th>\n      <th>sent_word_count_last</th>\n      <th>sent_word_count_sem</th>\n      <th>sent_word_count_q1</th>\n      <th>sent_word_count_median</th>\n      <th>sent_word_count_q3</th>\n      <th>sent_word_count_skew</th>\n      <th>sent_word_count_kurt</th>\n      <th>sent_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>106.142857</td>\n      <td>41.128050</td>\n      <td>31</td>\n      <td>196</td>\n      <td>31</td>\n      <td>89</td>\n      <td>10.991934</td>\n      <td>75.5</td>\n      <td>119.5</td>\n      <td>...</td>\n      <td>6</td>\n      <td>16</td>\n      <td>1.736577</td>\n      <td>12.25</td>\n      <td>21.0</td>\n      <td>22.00</td>\n      <td>-0.506007</td>\n      <td>-0.526754</td>\n      <td>256</td>\n      <td>001519c8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>107.666667</td>\n      <td>64.713287</td>\n      <td>19</td>\n      <td>226</td>\n      <td>19</td>\n      <td>143</td>\n      <td>16.708899</td>\n      <td>56.5</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>30</td>\n      <td>3.269872</td>\n      <td>12.00</td>\n      <td>20.0</td>\n      <td>31.00</td>\n      <td>0.391857</td>\n      <td>-0.935036</td>\n      <td>325</td>\n      <td>0022f953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19</td>\n      <td>133.842105</td>\n      <td>33.480115</td>\n      <td>73</td>\n      <td>189</td>\n      <td>139</td>\n      <td>161</td>\n      <td>7.680865</td>\n      <td>108.0</td>\n      <td>139.0</td>\n      <td>...</td>\n      <td>21</td>\n      <td>26</td>\n      <td>1.207599</td>\n      <td>17.50</td>\n      <td>21.0</td>\n      <td>26.50</td>\n      <td>-0.242560</td>\n      <td>-1.171619</td>\n      <td>408</td>\n      <td>0042269b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>86.846154</td>\n      <td>33.195999</td>\n      <td>39</td>\n      <td>144</td>\n      <td>99</td>\n      <td>80</td>\n      <td>9.206914</td>\n      <td>62.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>17</td>\n      <td>14</td>\n      <td>1.800997</td>\n      <td>11.00</td>\n      <td>15.0</td>\n      <td>18.00</td>\n      <td>0.656055</td>\n      <td>-0.538051</td>\n      <td>208</td>\n      <td>0059420b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>86.812500</td>\n      <td>44.094170</td>\n      <td>22</td>\n      <td>182</td>\n      <td>75</td>\n      <td>22</td>\n      <td>11.023543</td>\n      <td>60.0</td>\n      <td>74.0</td>\n      <td>...</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.166927</td>\n      <td>11.00</td>\n      <td>12.5</td>\n      <td>18.25</td>\n      <td>1.148513</td>\n      <td>0.888421</td>\n      <td>255</td>\n      <td>0075873a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   sent_count  sent_len_mean  sent_len_std  sent_len_min  sent_len_max  \\\n0           1            2.0           NaN             2             2   \n1           1            1.0           NaN             1             1   \n\n   sent_len_first  sent_len_last  sent_len_sem  sent_len_q1  sent_len_median  \\\n0               2              2           NaN          2.0              2.0   \n1               1              1           NaN          1.0              1.0   \n\n   ...  sent_word_count_first  sent_word_count_last  sent_word_count_sem  \\\n0  ...                      1                     1                  NaN   \n1  ...                      1                     1                  NaN   \n\n   sent_word_count_q1  sent_word_count_median  sent_word_count_q3  \\\n0                 1.0                     1.0                 1.0   \n1                 1.0                     1.0                 1.0   \n\n   sent_word_count_skew  sent_word_count_kurt  sent_word_count_sum        id  \n0                   NaN                   NaN                    1  2222bbbb  \n1                   NaN                   NaN                    1  4444cccc  \n\n[2 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_count</th>\n      <th>sent_len_mean</th>\n      <th>sent_len_std</th>\n      <th>sent_len_min</th>\n      <th>sent_len_max</th>\n      <th>sent_len_first</th>\n      <th>sent_len_last</th>\n      <th>sent_len_sem</th>\n      <th>sent_len_q1</th>\n      <th>sent_len_median</th>\n      <th>...</th>\n      <th>sent_word_count_first</th>\n      <th>sent_word_count_last</th>\n      <th>sent_word_count_sem</th>\n      <th>sent_word_count_q1</th>\n      <th>sent_word_count_median</th>\n      <th>sent_word_count_q3</th>\n      <th>sent_word_count_skew</th>\n      <th>sent_word_count_kurt</th>\n      <th>sent_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2222bbbb</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>4444cccc</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"次に、段落ごとのエッセイの特徴量を抜き出す。  \n改行(\\n)をキーとして、エッセイを分割し特徴量(文章の平均や分散など)を抜き出す関数を定義する。  \n- split_essays_into_paragraph関数 : エッセイを段落ごとに分割し、その文章の長さや単語数を返却する関数\n- compute_sentence_aggregations関数 : 段落ごとに分割したエッセイ情報から文字数や平均文字数などの情報を返却する関数","metadata":{}},{"cell_type":"code","source":"def split_essays_into_paragraphs(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: x.split('\\n'))\n    essay_df = essay_df.explode('paragraph')\n    # Number of characters in paragraphs\n    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n    # Number of words in paragraphs\n    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_paragraph_aggregations(df):\n    paragraph_agg_df = pd.concat(\n        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    ) \n    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n    paragraph_agg_df['id'] = paragraph_agg_df.index\n    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n    return paragraph_agg_df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:03.389392Z","iopub.execute_input":"2023-11-30T12:18:03.390311Z","iopub.status.idle":"2023-11-30T12:18:03.398408Z","shell.execute_reply.started":"2023-11-30T12:18:03.390279Z","shell.execute_reply":"2023-11-30T12:18:03.397626Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Paragraph features for train dataset\ntrain_paragraph_df = split_essays_into_paragraphs(train_essays)\ntrain_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)\ntest_paragraph_df = split_essays_into_paragraphs(test_essays)\ntest_paragraph_agg_df = compute_paragraph_aggregations(test_paragraph_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:03.399330Z","iopub.execute_input":"2023-11-30T12:18:03.400216Z","iopub.status.idle":"2023-11-30T12:18:09.126126Z","shell.execute_reply.started":"2023-11-30T12:18:03.400186Z","shell.execute_reply":"2023-11-30T12:18:09.124971Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"この関数を実行することで、各エッセイにおける各段落の統計量が特徴量として取得できる。","metadata":{}},{"cell_type":"code","source":"display(train_paragraph_agg_df.head())\ndisplay(test_paragraph_agg_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:09.127553Z","iopub.execute_input":"2023-11-30T12:18:09.127893Z","iopub.status.idle":"2023-11-30T12:18:09.170204Z","shell.execute_reply.started":"2023-11-30T12:18:09.127863Z","shell.execute_reply":"2023-11-30T12:18:09.169342Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"   paragraph_count  paragraph_len_mean  paragraph_len_std  paragraph_len_min  \\\n0                3          508.000000         134.208793                390   \n1                6          278.166667          98.554384                176   \n2                6          429.500000         101.087586                296   \n3                3          384.000000          56.471232                347   \n4                5          283.400000         232.336609                 23   \n\n   paragraph_len_max  paragraph_len_first  paragraph_len_last  \\\n0                654                  390                 480   \n1                462                  240                 284   \n2                568                  491                 296   \n3                449                  347                 356   \n4                627                  351                  23   \n\n   paragraph_len_sem  paragraph_len_q1  paragraph_len_median  ...  \\\n0          77.485483            435.00                 480.0  ...   \n1          40.234659            228.75                 261.0  ...   \n2          41.268834            356.75                 444.5  ...   \n3          32.603681            351.50                 356.0  ...   \n4         103.904090            124.00                 292.0  ...   \n\n   paragraph_word_count_first  paragraph_word_count_last  \\\n0                          71                         86   \n1                          53                         60   \n2                          79                         45   \n3                          62                         65   \n4                          61                          3   \n\n   paragraph_word_count_sem  paragraph_word_count_q1  \\\n0                 11.976829                    78.50   \n1                  8.316316                    47.75   \n2                  6.926599                    55.50   \n3                  5.897269                    63.50   \n4                 18.706683                    26.00   \n\n   paragraph_word_count_median  paragraph_word_count_q3  \\\n0                         86.0                    99.00   \n1                         56.5                    62.25   \n2                         73.5                    78.75   \n3                         65.0                    73.00   \n4                         52.0                    61.00   \n\n   paragraph_word_count_skew  paragraph_word_count_kurt  \\\n0                   0.770543                        NaN   \n1                   1.299614                   2.342703   \n2                  -0.502908                  -1.536764   \n3                   1.565482                        NaN   \n4                   0.686760                   0.722916   \n\n   paragraph_word_count_sum        id  \n0                       269  001519c8  \n1                       355  0022f953  \n2                       410  0042269b  \n3                       208  0059420b  \n4                       256  0075873a  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paragraph_count</th>\n      <th>paragraph_len_mean</th>\n      <th>paragraph_len_std</th>\n      <th>paragraph_len_min</th>\n      <th>paragraph_len_max</th>\n      <th>paragraph_len_first</th>\n      <th>paragraph_len_last</th>\n      <th>paragraph_len_sem</th>\n      <th>paragraph_len_q1</th>\n      <th>paragraph_len_median</th>\n      <th>...</th>\n      <th>paragraph_word_count_first</th>\n      <th>paragraph_word_count_last</th>\n      <th>paragraph_word_count_sem</th>\n      <th>paragraph_word_count_q1</th>\n      <th>paragraph_word_count_median</th>\n      <th>paragraph_word_count_q3</th>\n      <th>paragraph_word_count_skew</th>\n      <th>paragraph_word_count_kurt</th>\n      <th>paragraph_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>508.000000</td>\n      <td>134.208793</td>\n      <td>390</td>\n      <td>654</td>\n      <td>390</td>\n      <td>480</td>\n      <td>77.485483</td>\n      <td>435.00</td>\n      <td>480.0</td>\n      <td>...</td>\n      <td>71</td>\n      <td>86</td>\n      <td>11.976829</td>\n      <td>78.50</td>\n      <td>86.0</td>\n      <td>99.00</td>\n      <td>0.770543</td>\n      <td>NaN</td>\n      <td>269</td>\n      <td>001519c8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>278.166667</td>\n      <td>98.554384</td>\n      <td>176</td>\n      <td>462</td>\n      <td>240</td>\n      <td>284</td>\n      <td>40.234659</td>\n      <td>228.75</td>\n      <td>261.0</td>\n      <td>...</td>\n      <td>53</td>\n      <td>60</td>\n      <td>8.316316</td>\n      <td>47.75</td>\n      <td>56.5</td>\n      <td>62.25</td>\n      <td>1.299614</td>\n      <td>2.342703</td>\n      <td>355</td>\n      <td>0022f953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>429.500000</td>\n      <td>101.087586</td>\n      <td>296</td>\n      <td>568</td>\n      <td>491</td>\n      <td>296</td>\n      <td>41.268834</td>\n      <td>356.75</td>\n      <td>444.5</td>\n      <td>...</td>\n      <td>79</td>\n      <td>45</td>\n      <td>6.926599</td>\n      <td>55.50</td>\n      <td>73.5</td>\n      <td>78.75</td>\n      <td>-0.502908</td>\n      <td>-1.536764</td>\n      <td>410</td>\n      <td>0042269b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>384.000000</td>\n      <td>56.471232</td>\n      <td>347</td>\n      <td>449</td>\n      <td>347</td>\n      <td>356</td>\n      <td>32.603681</td>\n      <td>351.50</td>\n      <td>356.0</td>\n      <td>...</td>\n      <td>62</td>\n      <td>65</td>\n      <td>5.897269</td>\n      <td>63.50</td>\n      <td>65.0</td>\n      <td>73.00</td>\n      <td>1.565482</td>\n      <td>NaN</td>\n      <td>208</td>\n      <td>0059420b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>283.400000</td>\n      <td>232.336609</td>\n      <td>23</td>\n      <td>627</td>\n      <td>351</td>\n      <td>23</td>\n      <td>103.904090</td>\n      <td>124.00</td>\n      <td>292.0</td>\n      <td>...</td>\n      <td>61</td>\n      <td>3</td>\n      <td>18.706683</td>\n      <td>26.00</td>\n      <td>52.0</td>\n      <td>61.00</td>\n      <td>0.686760</td>\n      <td>0.722916</td>\n      <td>256</td>\n      <td>0075873a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   paragraph_count  paragraph_len_mean  paragraph_len_std  paragraph_len_min  \\\n0                1                 2.0                NaN                  2   \n1                1                 2.0                NaN                  2   \n2                1                 2.0                NaN                  2   \n\n   paragraph_len_max  paragraph_len_first  paragraph_len_last  \\\n0                  2                    2                   2   \n1                  2                    2                   2   \n2                  2                    2                   2   \n\n   paragraph_len_sem  paragraph_len_q1  paragraph_len_median  ...  \\\n0                NaN               2.0                   2.0  ...   \n1                NaN               2.0                   2.0  ...   \n2                NaN               2.0                   2.0  ...   \n\n   paragraph_word_count_first  paragraph_word_count_last  \\\n0                           3                          3   \n1                           1                          1   \n2                           2                          2   \n\n   paragraph_word_count_sem  paragraph_word_count_q1  \\\n0                       NaN                      3.0   \n1                       NaN                      1.0   \n2                       NaN                      2.0   \n\n   paragraph_word_count_median  paragraph_word_count_q3  \\\n0                          3.0                      3.0   \n1                          1.0                      1.0   \n2                          2.0                      2.0   \n\n   paragraph_word_count_skew  paragraph_word_count_kurt  \\\n0                        NaN                        NaN   \n1                        NaN                        NaN   \n2                        NaN                        NaN   \n\n   paragraph_word_count_sum        id  \n0                         3  0000aaaa  \n1                         1  2222bbbb  \n2                         2  4444cccc  \n\n[3 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paragraph_count</th>\n      <th>paragraph_len_mean</th>\n      <th>paragraph_len_std</th>\n      <th>paragraph_len_min</th>\n      <th>paragraph_len_max</th>\n      <th>paragraph_len_first</th>\n      <th>paragraph_len_last</th>\n      <th>paragraph_len_sem</th>\n      <th>paragraph_len_q1</th>\n      <th>paragraph_len_median</th>\n      <th>...</th>\n      <th>paragraph_word_count_first</th>\n      <th>paragraph_word_count_last</th>\n      <th>paragraph_word_count_sem</th>\n      <th>paragraph_word_count_q1</th>\n      <th>paragraph_word_count_median</th>\n      <th>paragraph_word_count_q3</th>\n      <th>paragraph_word_count_skew</th>\n      <th>paragraph_word_count_kurt</th>\n      <th>paragraph_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0000aaaa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2222bbbb</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>4444cccc</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"3番目の特徴量作成として、キーロガー情報から各種統計情報を抜き出すためのPreprocessorクラスを実行する。作成する特徴量は以下の項目を作成する。\n- ラグ特徴量 : 同一IDのキーロガー情報をshift関数で任意にずらし、執筆時間の差や単語数の差を取得する。\n- InputやRemove/Cutなどのactivity情報の数(activity_counts関数)\n- それぞれの生徒がエッセイを書き上げるまでに記録されたキーロガー情報のイベント数(event_counts関数)\n- 書き込みや消去などのテキスト変更回数(text_change_counts関数)\n- 句読点の回数(match_punctuations関数)\n- 入力文字の統計量(get_input_words関数)","metadata":{}},{"cell_type":"code","source":"# The following code comes almost Abdullah's notebook: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n# Abdullah's code is based on work shared in previous notebooks (e.g., https://www.kaggle.com/code/hengzheng/link-writing-simple-lgbm-baseline)\n\nfrom collections import defaultdict\n\nclass Preprocessor:\n    \n    def __init__(self, seed):\n        self.seed = seed\n        \n        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n        \n        self.idf = defaultdict(float)\n    \n    def activity_counts(self, df):\n        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['activity'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.activities:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n\n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n    def event_counts(self, df, colname):\n        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df[colname].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.events:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n    def text_change_counts(self, df):\n        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['text_change'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.text_changes:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n            \n        return ret\n\n    def match_punctuations(self, df):\n        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['down_event'].values):\n            cnt = 0\n            items = list(Counter(li).items())\n            for item in items:\n                k, v = item[0], item[1]\n                if k in self.punctuations:\n                    cnt += v\n            ret.append(cnt)\n        ret = pd.DataFrame({'punct_cnt': ret})\n        return ret\n\n    def get_input_words(self, df):\n        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df.drop(['text_change'], axis=1, inplace=True)\n        return tmp_df\n    \n    def make_feats(self, df):\n        \n        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n        \n        print(\"Engineering time data\")\n        for gap in self.gaps:\n            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n\n        print(\"Engineering cursor position data\")\n        for gap in self.gaps:\n            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n\n        print(\"Engineering word count data\")\n        for gap in self.gaps:\n            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n        \n        print(\"Engineering statistical summaries for features\")\n        feats_stat = [\n            ('event_id', ['max']),\n            ('up_time', ['max']),\n            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n            ('activity', ['nunique']),\n            ('down_event', ['nunique']),\n            ('up_event', ['nunique']),\n            ('text_change', ['nunique']),\n            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean']),\n            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean'])]\n        for gap in self.gaps:\n            feats_stat.extend([\n                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt])\n            ])\n        \n        pbar = tqdm(feats_stat)\n        for item in pbar:\n            colname, methods = item[0], item[1]\n            for method in methods:\n                pbar.set_postfix()\n                if isinstance(method, str):\n                    method_name = method\n                else:\n                    method_name = method.__name__\n                pbar.set_postfix(column=colname, method=method_name)\n                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n                feats = feats.merge(tmp_df, on='id', how='left')\n\n        print(\"Engineering activity counts data\")\n        tmp_df = self.activity_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering event counts data\")\n        tmp_df = self.event_counts(df, 'down_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        tmp_df = self.event_counts(df, 'up_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering text change counts data\")\n        tmp_df = self.text_change_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering punctuation counts data\")\n        tmp_df = self.match_punctuations(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n\n        print(\"Engineering input words data\")\n        tmp_df = self.get_input_words(df)\n        feats = pd.merge(feats, tmp_df, on='id', how='left')\n\n        print(\"Engineering ratios data\")\n        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n\n        return feats","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:09.171780Z","iopub.execute_input":"2023-11-30T12:18:09.172151Z","iopub.status.idle":"2023-11-30T12:18:09.211413Z","shell.execute_reply.started":"2023-11-30T12:18:09.172119Z","shell.execute_reply":"2023-11-30T12:18:09.210256Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"preprocessor = Preprocessor(seed=42)\ntrain_feats = preprocessor.make_feats(train_logs)\ntest_feats = preprocessor.make_feats(test_logs)\nnan_cols = train_feats.columns[train_feats.isna().any()].tolist()\ntrain_feats = train_feats.drop(columns=nan_cols)\ntest_feats = test_feats.drop(columns=nan_cols)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:18:09.213332Z","iopub.execute_input":"2023-11-30T12:18:09.213826Z","iopub.status.idle":"2023-11-30T12:21:56.121486Z","shell.execute_reply.started":"2023-11-30T12:18:09.213786Z","shell.execute_reply":"2023-11-30T12:21:56.118347Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Engineering time data\nEngineering cursor position data\nEngineering word count data\nEngineering statistical summaries for features\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 33/33 [03:03<00:00,  5.55s/it, column=word_count_change100, method=kurt]         \n","output_type":"stream"},{"name":"stdout","text":"Engineering activity counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 6506.83it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering event counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 6180.00it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n100%|██████████| 2471/2471 [00:00<00:00, 6105.97it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering text change counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 6072.22it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering punctuation counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 6173.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Engineering input words data\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/3946551957.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n/tmp/ipykernel_47/3946551957.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n","output_type":"stream"},{"name":"stdout","text":"Engineering ratios data\nEngineering time data\nEngineering cursor position data\nEngineering word count data\nEngineering statistical summaries for features\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 33/33 [00:02<00:00, 14.08it/s, column=word_count_change100, method=kurt]         \n","output_type":"stream"},{"name":"stdout","text":"Engineering activity counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 6963.43it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering event counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 3387.06it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n100%|██████████| 3/3 [00:00<00:00, 20262.34it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering text change counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 12958.71it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering punctuation counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 19815.61it/s]\n/tmp/ipykernel_47/3946551957.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n/tmp/ipykernel_47/3946551957.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n","output_type":"stream"},{"name":"stdout","text":"Engineering input words data\nEngineering ratios data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"上記の関数を実行すると、キーロガー情報（train_logsやtest_logs）をもとに特徴量を抜き出す。詳細は[https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs](https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs)参照","metadata":{}},{"cell_type":"code","source":"display(train_feats.head())\ndisplay(test_feats.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:21:56.124609Z","iopub.execute_input":"2023-11-30T12:21:56.125356Z","iopub.status.idle":"2023-11-30T12:21:56.192331Z","shell.execute_reply.started":"2023-11-30T12:21:56.125279Z","shell.execute_reply":"2023-11-30T12:21:56.191078Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id  event_id_max  up_time_max  action_time_max  action_time_min  \\\n0  001519c8          2557      1801969             2259                0   \n1  0022f953          2454      1788969             1758                0   \n2  0042269b          4136      1771669             3005                0   \n3  0059420b          1556      1404469              806                0   \n4  0075873a          2531      1662472              701                0   \n\n   action_time_mean  action_time_std  action_time_quantile  action_time_sem  \\\n0        116.246774        91.797374                 112.0         1.815369   \n1        112.221271        55.431189                 115.0         1.118966   \n2        101.837766        82.383766                  94.0         1.281007   \n3        121.848329       113.768226                 110.0         2.884139   \n4        123.943896        62.082013                 129.0         1.234013   \n\n   action_time_sum  ...  text_change_14_count  punct_cnt  input_word_count  \\\n0           297243  ...                  -inf         37               366   \n1           275391  ...                  -inf         53               385   \n2           421201  ...                  -inf         47               627   \n3           189596  ...                  -inf         18               251   \n4           313702  ...                  -inf         66               412   \n\n   input_word_length_mean  input_word_length_max  input_word_length_std  \\\n0                5.325137                     20               3.487804   \n1                4.410390                     33               3.199496   \n2                5.446571                     25               3.474895   \n3                4.609562                     19               2.949601   \n4                4.766990                     18               2.986064   \n\n   word_time_ratio  word_event_ratio  event_time_ratio  idle_time_ratio  \n0         0.000142          0.100117          0.001419         0.832534  \n1         0.000181          0.131622          0.001372         0.828944  \n2         0.000228          0.097679          0.002335         0.759751  \n3         0.000147          0.132391          0.001108         0.835531  \n4         0.000152          0.099565          0.001522         0.764103  \n\n[5 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id_max</th>\n      <th>up_time_max</th>\n      <th>action_time_max</th>\n      <th>action_time_min</th>\n      <th>action_time_mean</th>\n      <th>action_time_std</th>\n      <th>action_time_quantile</th>\n      <th>action_time_sem</th>\n      <th>action_time_sum</th>\n      <th>...</th>\n      <th>text_change_14_count</th>\n      <th>punct_cnt</th>\n      <th>input_word_count</th>\n      <th>input_word_length_mean</th>\n      <th>input_word_length_max</th>\n      <th>input_word_length_std</th>\n      <th>word_time_ratio</th>\n      <th>word_event_ratio</th>\n      <th>event_time_ratio</th>\n      <th>idle_time_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>2557</td>\n      <td>1801969</td>\n      <td>2259</td>\n      <td>0</td>\n      <td>116.246774</td>\n      <td>91.797374</td>\n      <td>112.0</td>\n      <td>1.815369</td>\n      <td>297243</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>37</td>\n      <td>366</td>\n      <td>5.325137</td>\n      <td>20</td>\n      <td>3.487804</td>\n      <td>0.000142</td>\n      <td>0.100117</td>\n      <td>0.001419</td>\n      <td>0.832534</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022f953</td>\n      <td>2454</td>\n      <td>1788969</td>\n      <td>1758</td>\n      <td>0</td>\n      <td>112.221271</td>\n      <td>55.431189</td>\n      <td>115.0</td>\n      <td>1.118966</td>\n      <td>275391</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>53</td>\n      <td>385</td>\n      <td>4.410390</td>\n      <td>33</td>\n      <td>3.199496</td>\n      <td>0.000181</td>\n      <td>0.131622</td>\n      <td>0.001372</td>\n      <td>0.828944</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0042269b</td>\n      <td>4136</td>\n      <td>1771669</td>\n      <td>3005</td>\n      <td>0</td>\n      <td>101.837766</td>\n      <td>82.383766</td>\n      <td>94.0</td>\n      <td>1.281007</td>\n      <td>421201</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>47</td>\n      <td>627</td>\n      <td>5.446571</td>\n      <td>25</td>\n      <td>3.474895</td>\n      <td>0.000228</td>\n      <td>0.097679</td>\n      <td>0.002335</td>\n      <td>0.759751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0059420b</td>\n      <td>1556</td>\n      <td>1404469</td>\n      <td>806</td>\n      <td>0</td>\n      <td>121.848329</td>\n      <td>113.768226</td>\n      <td>110.0</td>\n      <td>2.884139</td>\n      <td>189596</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>18</td>\n      <td>251</td>\n      <td>4.609562</td>\n      <td>19</td>\n      <td>2.949601</td>\n      <td>0.000147</td>\n      <td>0.132391</td>\n      <td>0.001108</td>\n      <td>0.835531</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0075873a</td>\n      <td>2531</td>\n      <td>1662472</td>\n      <td>701</td>\n      <td>0</td>\n      <td>123.943896</td>\n      <td>62.082013</td>\n      <td>129.0</td>\n      <td>1.234013</td>\n      <td>313702</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>66</td>\n      <td>412</td>\n      <td>4.766990</td>\n      <td>18</td>\n      <td>2.986064</td>\n      <td>0.000152</td>\n      <td>0.099565</td>\n      <td>0.001522</td>\n      <td>0.764103</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 287 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         id  event_id_max  up_time_max  action_time_max  action_time_min  \\\n0  0000aaaa             2       760160               87               85   \n1  2222bbbb             2       712023               67               46   \n2  4444cccc             2       635641               94               56   \n\n   action_time_mean  action_time_std  action_time_quantile  action_time_sem  \\\n0              86.0         1.414214                  86.0              1.0   \n1              56.5        14.849242                  56.5             10.5   \n2              75.0        26.870058                  75.0             19.0   \n\n   action_time_sum  ...  text_change_14_count  punct_cnt  input_word_count  \\\n0              172  ...                  -inf          0                 0   \n1              113  ...                  -inf          0                 1   \n2              150  ...                  -inf          0                 1   \n\n   input_word_length_mean  input_word_length_max  input_word_length_std  \\\n0                     0.0                      0                    0.0   \n1                     2.0                      2                    0.0   \n2                     1.0                      1                    0.0   \n\n   word_time_ratio  word_event_ratio  event_time_ratio  idle_time_ratio  \n0         0.000000               0.0          0.000003         0.554561  \n1         0.000001               0.5          0.000003        -0.592005  \n2         0.000002               0.5          0.000003        -0.708962  \n\n[3 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id_max</th>\n      <th>up_time_max</th>\n      <th>action_time_max</th>\n      <th>action_time_min</th>\n      <th>action_time_mean</th>\n      <th>action_time_std</th>\n      <th>action_time_quantile</th>\n      <th>action_time_sem</th>\n      <th>action_time_sum</th>\n      <th>...</th>\n      <th>text_change_14_count</th>\n      <th>punct_cnt</th>\n      <th>input_word_count</th>\n      <th>input_word_length_mean</th>\n      <th>input_word_length_max</th>\n      <th>input_word_length_std</th>\n      <th>word_time_ratio</th>\n      <th>word_event_ratio</th>\n      <th>event_time_ratio</th>\n      <th>idle_time_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>2</td>\n      <td>760160</td>\n      <td>87</td>\n      <td>85</td>\n      <td>86.0</td>\n      <td>1.414214</td>\n      <td>86.0</td>\n      <td>1.0</td>\n      <td>172</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000003</td>\n      <td>0.554561</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2222bbbb</td>\n      <td>2</td>\n      <td>712023</td>\n      <td>67</td>\n      <td>46</td>\n      <td>56.5</td>\n      <td>14.849242</td>\n      <td>56.5</td>\n      <td>10.5</td>\n      <td>113</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.000001</td>\n      <td>0.5</td>\n      <td>0.000003</td>\n      <td>-0.592005</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4444cccc</td>\n      <td>2</td>\n      <td>635641</td>\n      <td>94</td>\n      <td>56</td>\n      <td>75.0</td>\n      <td>26.870058</td>\n      <td>75.0</td>\n      <td>19.0</td>\n      <td>150</td>\n      <td>...</td>\n      <td>-inf</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000002</td>\n      <td>0.5</td>\n      <td>0.000003</td>\n      <td>-0.708962</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 287 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Code for additional aggregations comes from here: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n\ntrain_agg_fe_df = train_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(\n    ['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntrain_agg_fe_df.columns = ['_'.join(x) for x in train_agg_fe_df.columns]\ntrain_agg_fe_df = train_agg_fe_df.add_prefix(\"tmp_\")\ntrain_agg_fe_df.reset_index(inplace=True)\n\ntest_agg_fe_df = test_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(\n    ['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntest_agg_fe_df.columns = ['_'.join(x) for x in test_agg_fe_df.columns]\ntest_agg_fe_df = test_agg_fe_df.add_prefix(\"tmp_\")\ntest_agg_fe_df.reset_index(inplace=True)\n\ntrain_feats = train_feats.merge(train_agg_fe_df, on='id', how='left')\ntest_feats = test_feats.merge(test_agg_fe_df, on='id', how='left')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:21:56.196620Z","iopub.execute_input":"2023-11-30T12:21:56.197027Z","iopub.status.idle":"2023-11-30T12:22:02.612187Z","shell.execute_reply.started":"2023-11-30T12:21:56.196995Z","shell.execute_reply":"2023-11-30T12:22:02.608538Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Adding the additional features to the original feature set\n\ntrain_feats = train_feats.merge(train_sent_agg_df, on='id', how='left')\ntrain_feats = train_feats.merge(train_paragraph_agg_df, on='id', how='left')\ntest_feats = test_feats.merge(test_sent_agg_df, on='id', how='left')\ntest_feats = test_feats.merge(test_paragraph_agg_df, on='id', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:22:02.615338Z","iopub.execute_input":"2023-11-30T12:22:02.616969Z","iopub.status.idle":"2023-11-30T12:22:02.671544Z","shell.execute_reply.started":"2023-11-30T12:22:02.616894Z","shell.execute_reply":"2023-11-30T12:22:02.668784Z"},"trusted":true},"execution_count":21,"outputs":[]}]}