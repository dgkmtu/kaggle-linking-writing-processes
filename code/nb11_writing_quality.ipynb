{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59291,"databundleVersionId":6678907,"sourceType":"competition"},{"sourceId":6971449,"sourceType":"datasetVersion","datasetId":3992884},{"sourceId":6973319,"sourceType":"datasetVersion","datasetId":3949123},{"sourceId":150384981,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 目的\n\n本コンペティションは、学生にエッセイを書かせ、その詳細な動作(入力や消去、移動など)からエッセイの採点結果を予想するテーブルコンペである。  \n  \nこのnotebookでは、前処理から学習、提出までの流れをまとめる。  \nなお、参考にしたnotebookは以下の通り。  \n[https://www.kaggle.com/code/alexryzhkov/lgbm-and-nn-on-sentences/notebook](https://www.kaggle.com/code/alexryzhkov/lgbm-and-nn-on-sentences/notebook)","metadata":{}},{"cell_type":"markdown","source":"## 1. LightAutoMLのインストール\n事前に[LightAutoML 038 dependecies](https://www.kaggle.com/code/alexryzhkov/lightautoml-038-dependecies)をAdd Dataしておく。","metadata":{}},{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies lightautoml==0.3.8\n!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies pandas==2.0.3","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-29T11:56:24.150294Z","iopub.execute_input":"2023-11-29T11:56:24.151194Z","iopub.status.idle":"2023-11-29T11:57:00.729171Z","shell.execute_reply.started":"2023-11-29T11:56:24.151157Z","shell.execute_reply":"2023-11-29T11:57:00.728283Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/lightautoml-0.3.8-py3-none-any.whl\nProcessing /kaggle/input/lightautoml-038-dependecies/AutoWoE-1.3.2-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/cmaes-0.10.0-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.24)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/joblib-1.2.0-py3-none-any.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/json2html-1.3.0.tar.gz (from lightautoml==0.3.8)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing /kaggle/input/lightautoml-038-dependecies/lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (from lightautoml==0.3.8)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.24.3)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.4.0)\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/poetry_core-1.8.1-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (6.0.1)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.12.2)\nRequirement already satisfied: statsmodels<=0.14.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.14.0)\nRequirement already satisfied: torch<=2.0.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (2.0.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (4.66.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/StrEnum-0.4.15-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (3.7.3)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (7.4.3)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (2023.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (1.11.3)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinx-7.2.6-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (0.2.4)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (5.16.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (1.16.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml==0.3.8) (0.41.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml==0.3.8) (2.8.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (0.5.3)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.12)\nRequirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (2.3.1)\nRequirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (0.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml==0.3.8) (2.1.3)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (1.12.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (6.7.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (2.0.20)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml==0.3.8) (2.0.2)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml==0.3.8) (8.2.3)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.2.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.1.3)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.16.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.12.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/alabaster-0.7.13-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/imagesize-1.4.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.31.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (2023.7.22)\nBuilding wheels for collected packages: json2html\n  Building wheel for json2html (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7591 sha256=e19272e3d939fcc20ad3287f4ad4466cf6260bdacad2178d767c87248e0d9b97\n  Stored in directory: /root/.cache/pip/wheels/03/04/0d/34912ecabd9128a537a032c0fc15c6c46e734fb5fe3a14536c\nSuccessfully built json2html\nInstalling collected packages: StrEnum, json2html, sphinxcontrib-jsmath, poetry-core, joblib, imagesize, cmaes, alabaster, pandas, lightgbm, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, autowoe, lightautoml\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.3.2\n    Uninstalling joblib-1.3.2:\n      Successfully uninstalled joblib-1.3.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.0.3\n    Uninstalling pandas-2.0.3:\n      Successfully uninstalled pandas-2.0.3\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 3.3.2\n    Uninstalling lightgbm-3.3.2:\n      Successfully uninstalled lightgbm-3.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-0.7.13 autowoe-1.3.2 cmaes-0.10.0 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8 lightgbm-3.2.1 pandas-1.5.3 poetry-core-1.8.1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\nLooking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\nInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Uninstalling pandas-1.5.3:\n      Successfully uninstalled pandas-1.5.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nlightautoml 0.3.8 requires pandas<2.0.0, but you have pandas 2.0.3 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-2.0.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Import","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport gc\nimport os\nimport itertools\nimport pickle\nimport re\nimport time\nfrom random import choice, choices\nfrom functools import reduce\nfrom tqdm import tqdm\nfrom itertools import cycle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom functools import reduce\nfrom itertools import cycle\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nfrom sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\nimport lightgbm as lgb\nimport copy","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:00.731014Z","iopub.execute_input":"2023-11-29T11:57:00.731298Z","iopub.status.idle":"2023-11-29T11:57:03.872407Z","shell.execute_reply.started":"2023-11-29T11:57:00.731274Z","shell.execute_reply":"2023-11-29T11:57:03.871388Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 3. データの読み込み\n初期に用意される入力データは、以下の4つが用意されている。\n- train_logs.csv : キーロガーの記録(学習データ)\n- train_scores.csv : エッセイの採点結果(学習データ)\n- test_logs.csv : キーロガーの記録(テストデータ)\n- sample_submission.csv : 提出用csvファイル","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = '../input/linking-writing-processes-to-writing-quality'\ntrain_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\ntrain_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\ntest_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\nss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:03.873539Z","iopub.execute_input":"2023-11-29T11:57:03.873872Z","iopub.status.idle":"2023-11-29T11:57:15.410339Z","shell.execute_reply.started":"2023-11-29T11:57:03.873817Z","shell.execute_reply":"2023-11-29T11:57:15.409350Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"読み込んだデータの概要を確認する。  \n各データの形状および先頭5行をみると、train_logsとtest_logsには「生徒のid」や「アクションの開始・終了の時間」、「アクションの種類(InputやRemoveなど)」などの情報が格納されている。  \n一方で、train_scoresには「生徒のid」と「エッセイの採点結果」が格納されている。  \n提出の形式は、「生徒のid」および「エッセイの採点結果」を提出するようだ。","metadata":{}},{"cell_type":"code","source":"print(\"train_logs shape : \", train_logs.shape)\nprint(\"train_scores shape : \", train_scores.shape)\nprint(\"test_logs shape : \", test_logs.shape)\nprint(\"sample_submission shape : \", ss_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.412331Z","iopub.execute_input":"2023-11-29T11:57:15.412738Z","iopub.status.idle":"2023-11-29T11:57:15.418806Z","shell.execute_reply.started":"2023-11-29T11:57:15.412707Z","shell.execute_reply":"2023-11-29T11:57:15.417623Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"train_logs shape :  (8405898, 11)\ntrain_scores shape :  (2471, 2)\ntest_logs shape :  (6, 11)\nsample_submission shape :  (3, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"display(train_logs.head())\ndisplay(train_scores.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.422545Z","iopub.execute_input":"2023-11-29T11:57:15.422971Z","iopub.status.idle":"2023-11-29T11:57:15.453180Z","shell.execute_reply.started":"2023-11-29T11:57:15.422940Z","shell.execute_reply":"2023-11-29T11:57:15.452048Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id  event_id  down_time  up_time  action_time       activity  \\\n0  001519c8         1       4526     4557           31  Nonproduction   \n1  001519c8         2       4558     4962          404  Nonproduction   \n2  001519c8         3     106571   106571            0  Nonproduction   \n3  001519c8         4     106686   106777           91          Input   \n4  001519c8         5     107196   107323          127          Input   \n\n  down_event   up_event text_change  cursor_position  word_count  \n0  Leftclick  Leftclick    NoChange                0           0  \n1  Leftclick  Leftclick    NoChange                0           0  \n2      Shift      Shift    NoChange                0           0  \n3          q          q           q                1           1  \n4          q          q           q                2           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>1</td>\n      <td>4526</td>\n      <td>4557</td>\n      <td>31</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001519c8</td>\n      <td>2</td>\n      <td>4558</td>\n      <td>4962</td>\n      <td>404</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001519c8</td>\n      <td>3</td>\n      <td>106571</td>\n      <td>106571</td>\n      <td>0</td>\n      <td>Nonproduction</td>\n      <td>Shift</td>\n      <td>Shift</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001519c8</td>\n      <td>4</td>\n      <td>106686</td>\n      <td>106777</td>\n      <td>91</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001519c8</td>\n      <td>5</td>\n      <td>107196</td>\n      <td>107323</td>\n      <td>127</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"         id  score\n0  001519c8    3.5\n1  0022f953    3.5\n2  0042269b    6.0\n3  0059420b    2.0\n4  0075873a    4.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022f953</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0042269b</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0059420b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0075873a</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"display(test_logs.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.454553Z","iopub.execute_input":"2023-11-29T11:57:15.454916Z","iopub.status.idle":"2023-11-29T11:57:15.467551Z","shell.execute_reply.started":"2023-11-29T11:57:15.454884Z","shell.execute_reply":"2023-11-29T11:57:15.466564Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id  event_id  down_time  up_time  action_time activity down_event  \\\n0  0000aaaa         1     338433   338518           85    Input      Space   \n1  0000aaaa         2     760073   760160           87    Input      Space   \n2  2222bbbb         1     711956   712023           67    Input          q   \n3  2222bbbb         2     290502   290548           46    Input          q   \n4  4444cccc         1     635547   635641           94    Input      Space   \n\n  up_event text_change  cursor_position  word_count  \n0    Space                            0           0  \n1    Space                            1           0  \n2        q           q                0           1  \n3        q           q                1           1  \n4    Space                            0           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>1</td>\n      <td>338433</td>\n      <td>338518</td>\n      <td>85</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000aaaa</td>\n      <td>2</td>\n      <td>760073</td>\n      <td>760160</td>\n      <td>87</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222bbbb</td>\n      <td>1</td>\n      <td>711956</td>\n      <td>712023</td>\n      <td>67</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2222bbbb</td>\n      <td>2</td>\n      <td>290502</td>\n      <td>290548</td>\n      <td>46</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4444cccc</td>\n      <td>1</td>\n      <td>635547</td>\n      <td>635641</td>\n      <td>94</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"続いて、作成したエッセイの情報を読み込む。  \nこの情報はtrain_logsのキーロガー情報を結合し、各生徒が作成したエッセイを復元したデータである。実際に入力した文字は\"q\"に置き換えられているが、エッセイの長さなどの重要な情報が取得可能となる。  \n\n<参考>  \n[https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features](https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features)","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv('../input/writing-quality-challenge-constructed-essays/train_essays_02.csv')\ntrain_essays.index = train_essays[\"Unnamed: 0\"]\ntrain_essays.index.name = None\ntrain_essays.drop(columns=[\"Unnamed: 0\"], inplace=True)\ntrain_essays.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.468767Z","iopub.execute_input":"2023-11-29T11:57:15.469115Z","iopub.status.idle":"2023-11-29T11:57:15.598834Z","shell.execute_reply.started":"2023-11-29T11:57:15.469086Z","shell.execute_reply":"2023-11-29T11:57:15.598003Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                      essay\n001519c8  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...\n0022f953  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...\n0042269b  qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...\n0059420b  qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...\n0075873a  qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>001519c8</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n    </tr>\n    <tr>\n      <th>0022f953</th>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n    </tr>\n    <tr>\n      <th>0042269b</th>\n      <td>qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...</td>\n    </tr>\n    <tr>\n      <th>0059420b</th>\n      <td>qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...</td>\n    </tr>\n    <tr>\n      <th>0075873a</th>\n      <td>qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"また、テストデータについてもエッセイを復元する。  \nテストデータのエッセイは、以下の関数を使用して新たにエッセイを復元する。\n- processingInputs関数 : 各キーロガー記録からテキストの小部分を復元する関数(getEssays関数内で呼び出される。)\n- getEssays関数 : エッセイを復元する関数","metadata":{}},{"cell_type":"code","source":"def getEssays(df):\n    \"\"\"\n    エッセイの復元関数\n    [input]\n     df(pd.DataFrame) : キーロガー情報のデータフレーム\n    [output]\n     essayFrame(pd.DataFrame) : 復元したエッセイのデータフレーム\n    \"\"\"\n    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n    lastIndex = 0\n    essaySeries = pd.Series()\n    for index, valCount in enumerate(valCountsArr):\n        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n        lastIndex += valCount\n        essayText = \"\"\n        for Input in currTextInput.values:\n            if Input[0] == 'Replace':\n                replaceTxt = Input[2].split(' => ')\n                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] +\\\n                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n                continue\n            if Input[0] == 'Paste':\n                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n                continue\n            if Input[0] == 'Remove/Cut':\n                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n                continue\n            if \"M\" in Input[0]:\n                croppedTxt = Input[0][10:]\n                splitTxt = croppedTxt.split(' To ')\n                valueArr = [item.split(', ') for item in splitTxt]\n                moveData = (int(valueArr[0][0][1:]), \n                            int(valueArr[0][1][:-1]), \n                            int(valueArr[1][0][1:]), \n                            int(valueArr[1][1][:-1]))\n                if moveData[0] != moveData[2]:\n                    if moveData[0] < moveData[2]:\n                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n                    else:\n                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n                continue\n            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n        essaySeries[index] = essayText\n    essaySeries.index =  textInputDf['id'].unique()\n    return pd.DataFrame(essaySeries, columns=['essay'])","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.600258Z","iopub.execute_input":"2023-11-29T11:57:15.600792Z","iopub.status.idle":"2023-11-29T11:57:15.614014Z","shell.execute_reply.started":"2023-11-29T11:57:15.600751Z","shell.execute_reply":"2023-11-29T11:57:15.613230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Features for test dataset\ntest_essays = getEssays(test_logs)\ntest_essays.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.615937Z","iopub.execute_input":"2023-11-29T11:57:15.616284Z","iopub.status.idle":"2023-11-29T11:57:15.643354Z","shell.execute_reply.started":"2023-11-29T11:57:15.616255Z","shell.execute_reply":"2023-11-29T11:57:15.642376Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         essay\n0000aaaa      \n2222bbbb    qq\n4444cccc    q ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000aaaa</th>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2222bbbb</th>\n      <td>qq</td>\n    </tr>\n    <tr>\n      <th>4444cccc</th>\n      <td>q</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4.特徴量の作成","metadata":{}},{"cell_type":"markdown","source":"本節では、学習データを作成する準備として、各生徒のキーロガー情報から特徴量を作成していく。  \nまず、最初の準備としては復元したエッセイ情報からエッセイの特徴に関する情報（文字数や平均文字数などの情報）を作成する。  \nここでは四分位数の第一四分位数と第三四分位数を求める関数と、復元したテキスト情報から、エッセイの情報を抜き出す関数を定義する。  \n- q1関数 : 第一四分位数(25パーセンタイル)を返却する関数\n- q3関数 : 第三四分位数(75パーセンタイル)を返却する関数\n- split_essays_into_sentences関数 : 復元したエッセイを各文ごとに分割し、その文章の長さや単語数を返却する関数\n- compute_sentence_aggregations関数 : 各文ごとに分割したエッセイ情報から文字数や平均文字数などの情報を返却する関数","metadata":{}},{"cell_type":"code","source":"# 第一四分位数と第三四分位数を返却する関数\ndef q1(x):\n    return x.quantile(0.25)\ndef q3(x):\n    return x.quantile(0.75)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.644972Z","iopub.execute_input":"2023-11-29T11:57:15.645287Z","iopub.status.idle":"2023-11-29T11:57:15.654508Z","shell.execute_reply.started":"2023-11-29T11:57:15.645264Z","shell.execute_reply":"2023-11-29T11:57:15.653339Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', pd.DataFrame.kurt, 'sum']\n\ndef split_essays_into_sentences(df):\n    \"\"\"\n    エッセイ情報の各文別データフレーム作成関数\n    [input]\n     df(pd.DataFrame) : 復元したエッセイのデータフレーム\n    [output]\n     essay_df(pd.DataFrame) : 復元したエッセイのデータフレーム\n     \n    復元したエッセイ情報をもとに文の最後にあるカンマ(.)をキーとしてエッセイを分割する。\n    分割した各文の情報およびそれぞれの文章の長さや単語数の情報を追加して返却する。\n    \"\"\"\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n    essay_df = essay_df.explode('sent')\n    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n    # Number of characters in sentences\n    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n    # Number of words in sentences\n    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.sent_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_sentence_aggregations(df):\n    \"\"\"\n    エッセイ情報の統計情報取得関数\n    [input]\n     df(pd.DataFrame) : 復元したエッセイのデータフレーム\n    [output]\n     sent_agg_df(pd.DataFrame) : 復元したエッセイのデータフレーム\n     \n    カンマ(.)をキーとして分割したエッセイ情報のデータフレームから、生徒ごとの統計情報(平均や分散など)を\n    取得し返却する。\n    \"\"\"\n    sent_agg_df = pd.concat(\n        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    )\n    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n    sent_agg_df['id'] = sent_agg_df.index\n    sent_agg_df = sent_agg_df.reset_index(drop=True)\n    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n    return sent_agg_df","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.655581Z","iopub.execute_input":"2023-11-29T11:57:15.656442Z","iopub.status.idle":"2023-11-29T11:57:15.668899Z","shell.execute_reply.started":"2023-11-29T11:57:15.656409Z","shell.execute_reply":"2023-11-29T11:57:15.667765Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Word features for train dataset\ntrain_sent_df = split_essays_into_sentences(train_essays)\ntrain_sent_agg_df = compute_sentence_aggregations(train_sent_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:15.670121Z","iopub.execute_input":"2023-11-29T11:57:15.670480Z","iopub.status.idle":"2023-11-29T11:57:21.408849Z","shell.execute_reply.started":"2023-11-29T11:57:15.670451Z","shell.execute_reply":"2023-11-29T11:57:21.407895Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"この関数を実行することで、各エッセイにおける各文の統計量が特徴量として取得できる。","metadata":{}},{"cell_type":"code","source":"display(train_sent_agg_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:21.409861Z","iopub.execute_input":"2023-11-29T11:57:21.410113Z","iopub.status.idle":"2023-11-29T11:57:21.428816Z","shell.execute_reply.started":"2023-11-29T11:57:21.410089Z","shell.execute_reply":"2023-11-29T11:57:21.427967Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"   sent_count  sent_len_mean  sent_len_std  sent_len_min  sent_len_max  \\\n0          14     106.142857     41.128050            31           196   \n1          15     107.666667     64.713287            19           226   \n2          19     133.842105     33.480115            73           189   \n3          13      86.846154     33.195999            39           144   \n4          16      86.812500     44.094170            22           182   \n\n   sent_len_first  sent_len_last  sent_len_sem  sent_len_q1  sent_len_median  \\\n0              31             89     10.991934         75.5            119.5   \n1              19            143     16.708899         56.5             92.0   \n2             139            161      7.680865        108.0            139.0   \n3              99             80      9.206914         62.0             80.0   \n4              75             22     11.023543         60.0             74.0   \n\n   ...  sent_word_count_first  sent_word_count_last  sent_word_count_sem  \\\n0  ...                      6                    16             1.736577   \n1  ...                      3                    30             3.269872   \n2  ...                     21                    26             1.207599   \n3  ...                     17                    14             1.800997   \n4  ...                     11                     3             2.166927   \n\n   sent_word_count_q1  sent_word_count_median  sent_word_count_q3  \\\n0               12.25                    21.0               22.00   \n1               12.00                    20.0               31.00   \n2               17.50                    21.0               26.50   \n3               11.00                    15.0               18.00   \n4               11.00                    12.5               18.25   \n\n   sent_word_count_skew  sent_word_count_kurt  sent_word_count_sum        id  \n0             -0.506007             -0.526754                  256  001519c8  \n1              0.391857             -0.935036                  325  0022f953  \n2             -0.242560             -1.171619                  408  0042269b  \n3              0.656055             -0.538051                  208  0059420b  \n4              1.148513              0.888421                  255  0075873a  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_count</th>\n      <th>sent_len_mean</th>\n      <th>sent_len_std</th>\n      <th>sent_len_min</th>\n      <th>sent_len_max</th>\n      <th>sent_len_first</th>\n      <th>sent_len_last</th>\n      <th>sent_len_sem</th>\n      <th>sent_len_q1</th>\n      <th>sent_len_median</th>\n      <th>...</th>\n      <th>sent_word_count_first</th>\n      <th>sent_word_count_last</th>\n      <th>sent_word_count_sem</th>\n      <th>sent_word_count_q1</th>\n      <th>sent_word_count_median</th>\n      <th>sent_word_count_q3</th>\n      <th>sent_word_count_skew</th>\n      <th>sent_word_count_kurt</th>\n      <th>sent_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>106.142857</td>\n      <td>41.128050</td>\n      <td>31</td>\n      <td>196</td>\n      <td>31</td>\n      <td>89</td>\n      <td>10.991934</td>\n      <td>75.5</td>\n      <td>119.5</td>\n      <td>...</td>\n      <td>6</td>\n      <td>16</td>\n      <td>1.736577</td>\n      <td>12.25</td>\n      <td>21.0</td>\n      <td>22.00</td>\n      <td>-0.506007</td>\n      <td>-0.526754</td>\n      <td>256</td>\n      <td>001519c8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>107.666667</td>\n      <td>64.713287</td>\n      <td>19</td>\n      <td>226</td>\n      <td>19</td>\n      <td>143</td>\n      <td>16.708899</td>\n      <td>56.5</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>30</td>\n      <td>3.269872</td>\n      <td>12.00</td>\n      <td>20.0</td>\n      <td>31.00</td>\n      <td>0.391857</td>\n      <td>-0.935036</td>\n      <td>325</td>\n      <td>0022f953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19</td>\n      <td>133.842105</td>\n      <td>33.480115</td>\n      <td>73</td>\n      <td>189</td>\n      <td>139</td>\n      <td>161</td>\n      <td>7.680865</td>\n      <td>108.0</td>\n      <td>139.0</td>\n      <td>...</td>\n      <td>21</td>\n      <td>26</td>\n      <td>1.207599</td>\n      <td>17.50</td>\n      <td>21.0</td>\n      <td>26.50</td>\n      <td>-0.242560</td>\n      <td>-1.171619</td>\n      <td>408</td>\n      <td>0042269b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>86.846154</td>\n      <td>33.195999</td>\n      <td>39</td>\n      <td>144</td>\n      <td>99</td>\n      <td>80</td>\n      <td>9.206914</td>\n      <td>62.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>17</td>\n      <td>14</td>\n      <td>1.800997</td>\n      <td>11.00</td>\n      <td>15.0</td>\n      <td>18.00</td>\n      <td>0.656055</td>\n      <td>-0.538051</td>\n      <td>208</td>\n      <td>0059420b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>86.812500</td>\n      <td>44.094170</td>\n      <td>22</td>\n      <td>182</td>\n      <td>75</td>\n      <td>22</td>\n      <td>11.023543</td>\n      <td>60.0</td>\n      <td>74.0</td>\n      <td>...</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.166927</td>\n      <td>11.00</td>\n      <td>12.5</td>\n      <td>18.25</td>\n      <td>1.148513</td>\n      <td>0.888421</td>\n      <td>255</td>\n      <td>0075873a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"次に、","metadata":{}},{"cell_type":"code","source":"def split_essays_into_paragraphs(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: x.split('\\n'))\n    essay_df = essay_df.explode('paragraph')\n    # Number of characters in paragraphs\n    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n    # Number of words in paragraphs\n    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_paragraph_aggregations(df):\n    paragraph_agg_df = pd.concat(\n        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    ) \n    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n    paragraph_agg_df['id'] = paragraph_agg_df.index\n    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n    return paragraph_agg_df","metadata":{"execution":{"iopub.status.busy":"2023-11-29T11:57:21.431922Z","iopub.execute_input":"2023-11-29T11:57:21.432307Z","iopub.status.idle":"2023-11-29T11:57:21.443971Z","shell.execute_reply.started":"2023-11-29T11:57:21.432285Z","shell.execute_reply":"2023-11-29T11:57:21.442887Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Paragraph features for train dataset\ntrain_paragraph_df = split_essays_into_paragraphs(train_essays)\ntrain_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T12:00:31.183093Z","iopub.execute_input":"2023-11-29T12:00:31.183401Z","iopub.status.idle":"2023-11-29T12:00:36.934659Z","shell.execute_reply.started":"2023-11-29T12:00:31.183379Z","shell.execute_reply":"2023-11-29T12:00:36.933599Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"display(train_paragraph_df.head())\ndisplay(train_paragraph_agg_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-29T12:01:30.841433Z","iopub.execute_input":"2023-11-29T12:01:30.841734Z","iopub.status.idle":"2023-11-29T12:01:30.872029Z","shell.execute_reply.started":"2023-11-29T12:01:30.841711Z","shell.execute_reply":"2023-11-29T12:01:30.871325Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                               essay        id  \\\n0  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...  001519c8   \n1  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...  001519c8   \n2  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...  001519c8   \n3  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...  0022f953   \n4  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...  0022f953   \n\n                                                sent  \\\n0  [qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...   \n1  [qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...   \n2  [qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...   \n3  [qqqq qq qqqqqqqqqqq ,  qq qq qqq qqq qqq, qqq...   \n4  [qqqq qq qqqqqqqqqqq ,  qq qq qqq qqq qqq, qqq...   \n\n                                           paragraph  paragraph_len  \\\n0  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...            390   \n1  qq qq qqqq qqqq qqq qqqqqqqqq qqq qqqqqqq qq q...            654   \n2  qqqq qqq qqqqqq qqqqqqqqqq qqqqqqqqq qqqqq, qq...            480   \n3  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...            240   \n4       qqqqqq qq qqqq qqq qqq qqqq qqq qqqqqq qq...            462   \n\n   paragraph_word_count  \n0                    71  \n1                   112  \n2                    86  \n3                    53  \n4                    96  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n      <th>id</th>\n      <th>sent</th>\n      <th>paragraph</th>\n      <th>paragraph_len</th>\n      <th>paragraph_word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n      <td>001519c8</td>\n      <td>[qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...</td>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n      <td>390</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n      <td>001519c8</td>\n      <td>[qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...</td>\n      <td>qq qq qqqq qqqq qqq qqqqqqqqq qqq qqqqqqq qq q...</td>\n      <td>654</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n      <td>001519c8</td>\n      <td>[qqqqqqqqq qq qqqqq qq qqqq qqqq,   qqqqqq qqq...</td>\n      <td>qqqq qqq qqqqqq qqqqqqqqqq qqqqqqqqq qqqqq, qq...</td>\n      <td>480</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n      <td>0022f953</td>\n      <td>[qqqq qq qqqqqqqqqqq ,  qq qq qqq qqq qqq, qqq...</td>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n      <td>240</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n      <td>0022f953</td>\n      <td>[qqqq qq qqqqqqqqqqq ,  qq qq qqq qqq qqq, qqq...</td>\n      <td>qqqqqq qq qqqq qqq qqq qqqq qqq qqqqqq qq...</td>\n      <td>462</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   paragraph_count  paragraph_len_mean  paragraph_len_std  paragraph_len_min  \\\n0                3          508.000000         134.208793                390   \n1                6          278.166667          98.554384                176   \n2                6          429.500000         101.087586                296   \n3                3          384.000000          56.471232                347   \n4                5          283.400000         232.336609                 23   \n\n   paragraph_len_max  paragraph_len_first  paragraph_len_last  \\\n0                654                  390                 480   \n1                462                  240                 284   \n2                568                  491                 296   \n3                449                  347                 356   \n4                627                  351                  23   \n\n   paragraph_len_sem  paragraph_len_q1  paragraph_len_median  ...  \\\n0          77.485483            435.00                 480.0  ...   \n1          40.234659            228.75                 261.0  ...   \n2          41.268834            356.75                 444.5  ...   \n3          32.603681            351.50                 356.0  ...   \n4         103.904090            124.00                 292.0  ...   \n\n   paragraph_word_count_first  paragraph_word_count_last  \\\n0                          71                         86   \n1                          53                         60   \n2                          79                         45   \n3                          62                         65   \n4                          61                          3   \n\n   paragraph_word_count_sem  paragraph_word_count_q1  \\\n0                 11.976829                    78.50   \n1                  8.316316                    47.75   \n2                  6.926599                    55.50   \n3                  5.897269                    63.50   \n4                 18.706683                    26.00   \n\n   paragraph_word_count_median  paragraph_word_count_q3  \\\n0                         86.0                    99.00   \n1                         56.5                    62.25   \n2                         73.5                    78.75   \n3                         65.0                    73.00   \n4                         52.0                    61.00   \n\n   paragraph_word_count_skew  paragraph_word_count_kurt  \\\n0                   0.770543                        NaN   \n1                   1.299614                   2.342703   \n2                  -0.502908                  -1.536764   \n3                   1.565482                        NaN   \n4                   0.686760                   0.722916   \n\n   paragraph_word_count_sum        id  \n0                       269  001519c8  \n1                       355  0022f953  \n2                       410  0042269b  \n3                       208  0059420b  \n4                       256  0075873a  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paragraph_count</th>\n      <th>paragraph_len_mean</th>\n      <th>paragraph_len_std</th>\n      <th>paragraph_len_min</th>\n      <th>paragraph_len_max</th>\n      <th>paragraph_len_first</th>\n      <th>paragraph_len_last</th>\n      <th>paragraph_len_sem</th>\n      <th>paragraph_len_q1</th>\n      <th>paragraph_len_median</th>\n      <th>...</th>\n      <th>paragraph_word_count_first</th>\n      <th>paragraph_word_count_last</th>\n      <th>paragraph_word_count_sem</th>\n      <th>paragraph_word_count_q1</th>\n      <th>paragraph_word_count_median</th>\n      <th>paragraph_word_count_q3</th>\n      <th>paragraph_word_count_skew</th>\n      <th>paragraph_word_count_kurt</th>\n      <th>paragraph_word_count_sum</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>508.000000</td>\n      <td>134.208793</td>\n      <td>390</td>\n      <td>654</td>\n      <td>390</td>\n      <td>480</td>\n      <td>77.485483</td>\n      <td>435.00</td>\n      <td>480.0</td>\n      <td>...</td>\n      <td>71</td>\n      <td>86</td>\n      <td>11.976829</td>\n      <td>78.50</td>\n      <td>86.0</td>\n      <td>99.00</td>\n      <td>0.770543</td>\n      <td>NaN</td>\n      <td>269</td>\n      <td>001519c8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>278.166667</td>\n      <td>98.554384</td>\n      <td>176</td>\n      <td>462</td>\n      <td>240</td>\n      <td>284</td>\n      <td>40.234659</td>\n      <td>228.75</td>\n      <td>261.0</td>\n      <td>...</td>\n      <td>53</td>\n      <td>60</td>\n      <td>8.316316</td>\n      <td>47.75</td>\n      <td>56.5</td>\n      <td>62.25</td>\n      <td>1.299614</td>\n      <td>2.342703</td>\n      <td>355</td>\n      <td>0022f953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>429.500000</td>\n      <td>101.087586</td>\n      <td>296</td>\n      <td>568</td>\n      <td>491</td>\n      <td>296</td>\n      <td>41.268834</td>\n      <td>356.75</td>\n      <td>444.5</td>\n      <td>...</td>\n      <td>79</td>\n      <td>45</td>\n      <td>6.926599</td>\n      <td>55.50</td>\n      <td>73.5</td>\n      <td>78.75</td>\n      <td>-0.502908</td>\n      <td>-1.536764</td>\n      <td>410</td>\n      <td>0042269b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>384.000000</td>\n      <td>56.471232</td>\n      <td>347</td>\n      <td>449</td>\n      <td>347</td>\n      <td>356</td>\n      <td>32.603681</td>\n      <td>351.50</td>\n      <td>356.0</td>\n      <td>...</td>\n      <td>62</td>\n      <td>65</td>\n      <td>5.897269</td>\n      <td>63.50</td>\n      <td>65.0</td>\n      <td>73.00</td>\n      <td>1.565482</td>\n      <td>NaN</td>\n      <td>208</td>\n      <td>0059420b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>283.400000</td>\n      <td>232.336609</td>\n      <td>23</td>\n      <td>627</td>\n      <td>351</td>\n      <td>23</td>\n      <td>103.904090</td>\n      <td>124.00</td>\n      <td>292.0</td>\n      <td>...</td>\n      <td>61</td>\n      <td>3</td>\n      <td>18.706683</td>\n      <td>26.00</td>\n      <td>52.0</td>\n      <td>61.00</td>\n      <td>0.686760</td>\n      <td>0.722916</td>\n      <td>256</td>\n      <td>0075873a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}